{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96kvih9mXkNN"
      },
      "source": [
        "# **Youtube Videos Transcription with OpenAI's Whisper**\n",
        "\n",
        "[![blog post shield](https://img.shields.io/static/v1?label=&message=Blog%20post&color=blue&style=for-the-badge&logo=openai&link=https://openai.com/blog/whisper)](https://openai.com/blog/whisper)\n",
        "[![notebook shield](https://img.shields.io/static/v1?label=&message=Notebook&color=blue&style=for-the-badge&logo=googlecolab&link=https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)](https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)\n",
        "[![repository shield](https://img.shields.io/static/v1?label=&message=Repository&color=blue&style=for-the-badge&logo=github&link=https://github.com/openai/whisper)](https://github.com/openai/whisper)\n",
        "[![paper shield](https://img.shields.io/static/v1?label=&message=Paper&color=blue&style=for-the-badge&link=https://cdn.openai.com/papers/whisper.pdf)](https://cdn.openai.com/papers/whisper.pdf)\n",
        "[![model card shield](https://img.shields.io/static/v1?label=&message=Model%20card&color=blue&style=for-the-badge&link=https://github.com/openai/whisper/blob/main/model-card.md)](https://github.com/openai/whisper/blob/main/model-card.md)\n",
        "\n",
        "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\n",
        "\n",
        "This Notebook will guide you through the transcription of a Youtube video using Whisper. You'll be able to explore most inference parameters or use the Notebook as-is to store the transcript and video audio in your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QshUbLqpX7L4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: NVIDIA GeForce RTX 3090 (UUID: GPU-429fde5a-0fd7-55ff-201e-ed81d0791e8d)\n",
            "Sat May 20 17:07:01 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 531.29                 Driver Version: 531.29       CUDA Version: 12.1     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3090       WDDM | 00000000:01:00.0  On |                  N/A |\n",
            "|  0%   58C    P8               46W / 420W|   3461MiB / 24576MiB |      2%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      7280    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
            "|    0   N/A  N/A     16276    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     16996    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     18988    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     19228    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     21532    C+G   ...\\Local\\slack\\app-4.32.122\\slack.exe    N/A      |\n",
            "|    0   N/A  N/A     23724    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
            "|    0   N/A  N/A     24760    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
            "|    0   N/A  N/A     26000    C+G   ...ir\\CORSAIR iCUE 4 Software\\iCUE.exe    N/A      |\n",
            "|    0   N/A  N/A     27300    C+G   ...amapps\\common\\Terraria\\Terraria.exe    N/A      |\n",
            "|    0   N/A  N/A     28100    C+G   ...Desktop\\app-3.2.3\\GitHubDesktop.exe    N/A      |\n",
            "|    0   N/A  N/A     30816    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     32196    C+G   ...on\\113.0.1774.42\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A     32944    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
            "|    0   N/A  N/A     34124    C+G   ...AppData\\Roaming\\Spotify\\Spotify.exe    N/A      |\n",
            "|    0   N/A  N/A     34180    C+G   ...AIR iCUE 4 Software\\QmlRenderer.exe    N/A      |\n",
            "|    0   N/A  N/A     34192    C+G   ...al\\Discord\\app-1.0.9013\\Discord.exe    N/A      |\n",
            "|    0   N/A  N/A     34504    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A     36276    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
            "|    0   N/A  N/A     36948    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A     39652    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Check GPU type** üïµÔ∏è\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime &rarr; Change runtime type &rarr; Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "IfG0E_WbRFI0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-jbv3yffr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  ERROR: Error [WinError 2] The system cannot find the file specified while executing command git version\n",
            "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yt-dlp in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2023.3.4)\n",
            "Requirement already satisfied: mutagen in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yt-dlp) (1.46.0)\n",
            "Requirement already satisfied: pycryptodomex in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yt-dlp) (3.18.0)\n",
            "Requirement already satisfied: websockets in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yt-dlp) (11.0.3)\n",
            "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yt-dlp) (2022.12.7)\n",
            "Requirement already satisfied: brotli in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yt-dlp) (1.0.9)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Install libraries** üèóÔ∏è\n",
        "#@markdown This cell will take a little while to download several libraries, including Whisper.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install yt-dlp\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "1zwGAsr4sIgd"
      },
      "outputs": [],
      "source": [
        "# #@markdown # **Optional:** Save data in Google Drive üíæ\n",
        "# #@markdown Enter a Google Drive path and run this cell if you want to store the results inside Google Drive.\n",
        "\n",
        "# # Uncomment to copy generated images to drive, faster than downloading directly from colab in my experience.\n",
        "# from google.colab import drive\n",
        "# drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "# drive.mount(str(drive_mount_path))\n",
        "# drive_mount_path /= \"My Drive\"\n",
        "# #@markdown ---\n",
        "# drive_path = \"Colab Notebooks/Whisper Youtube\" #@param {type:\"string\"}\n",
        "# #@markdown ---\n",
        "# #@markdown **Run this cell again if you change your Google Drive path.**\n",
        "\n",
        "# drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "# drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "TMhrSq_GZ6kA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42G/1.42G [00:33<00:00, 45.8MiB/s]\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "**medium model is selected.**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown # **Model selection** üß†\n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "#@markdown | large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "Model = 'medium' #@param ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "if Model in whisper.available_models():\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is selected.**\"\n",
        "    ))\n",
        "else:\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is no longer available.**<br /> Please select one of the following:<br /> - {'<br /> - '.join(whisper.available_models())}\"\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "xYLPZQX9S7tU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/L_Guz73e6fw\n",
            "[youtube] L_Guz73e6fw: Downloading webpage\n",
            "[youtube] L_Guz73e6fw: Downloading android player API JSON\n",
            "[info] L_Guz73e6fw: Downloading 1 format(s): 140\n",
            "[dashsegments] Total fragments: 14\n",
            "[download] Destination: L_Guz73e6fw.m4a\n",
            "[download] 100% of  133.30MiB in 00:00:06 at 19.62MiB/s                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: L_Guz73e6fw: writing DASH m4a. Only some players support this container. Install ffmpeg to fix this automatically\n",
            "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
          ]
        },
        {
          "ename": "DownloadError",
          "evalue": "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPostProcessingError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3323\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[1;34m(self, info_dict)\u001b[0m\n\u001b[0;32m   3322\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3323\u001b[0m     replace_info_dict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpost_process(dl_filename, info_dict, files_to_move))\n\u001b[0;32m   3324\u001b[0m \u001b[39mexcept\u001b[39;00m PostProcessingError \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3502\u001b[0m, in \u001b[0;36mYoutubeDL.post_process\u001b[1;34m(self, filename, info, files_to_move)\u001b[0m\n\u001b[0;32m   3501\u001b[0m info[\u001b[39m'\u001b[39m\u001b[39m__files_to_move\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m files_to_move \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m-> 3502\u001b[0m info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_all_pps(\u001b[39m'\u001b[39;49m\u001b[39mpost_process\u001b[39;49m\u001b[39m'\u001b[39;49m, info, additional_pps\u001b[39m=\u001b[39;49minfo\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39m__postprocessors\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m   3503\u001b[0m info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_pp(MoveFilesAfterDownloadPP(\u001b[39mself\u001b[39m), info)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3484\u001b[0m, in \u001b[0;36mYoutubeDL.run_all_pps\u001b[1;34m(self, key, info, additional_pps)\u001b[0m\n\u001b[0;32m   3483\u001b[0m \u001b[39mfor\u001b[39;00m pp \u001b[39min\u001b[39;00m (additional_pps \u001b[39mor\u001b[39;00m []) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pps[key]:\n\u001b[1;32m-> 3484\u001b[0m     info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_pp(pp, info)\n\u001b[0;32m   3485\u001b[0m \u001b[39mreturn\u001b[39;00m info\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3462\u001b[0m, in \u001b[0;36mYoutubeDL.run_pp\u001b[1;34m(self, pp, infodict)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3462\u001b[0m     files_to_delete, infodict \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39;49mrun(infodict)\n\u001b[0;32m   3463\u001b[0m \u001b[39mexcept\u001b[39;00m PostProcessingError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   3464\u001b[0m     \u001b[39m# Must be True and not 'only_download'\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\postprocessor\\common.py:24\u001b[0m, in \u001b[0;36mPostProcessorMetaClass.run_wrapper.<locals>.run\u001b[1;34m(self, info, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_progress({\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mstarted\u001b[39m\u001b[39m'\u001b[39m}, info_copy)\n\u001b[1;32m---> 24\u001b[0m ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, info, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\postprocessor\\common.py:129\u001b[0m, in \u001b[0;36mPostProcessor._restrict_to.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, info)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mif\u001b[39;00m allowed[format_type]:\n\u001b[1;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, info)\n\u001b[0;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\postprocessor\\ffmpeg.py:488\u001b[0m, in \u001b[0;36mFFmpegExtractAudioPP.run\u001b[1;34m(self, information)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[39mreturn\u001b[39;00m [], information\n\u001b[1;32m--> 488\u001b[0m filecodec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_audio_codec(path)\n\u001b[0;32m    489\u001b[0m \u001b[39mif\u001b[39;00m filecodec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\postprocessor\\ffmpeg.py:241\u001b[0m, in \u001b[0;36mFFmpegPostProcessor.get_audio_codec\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobe_available \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavailable:\n\u001b[1;32m--> 241\u001b[0m     \u001b[39mraise\u001b[39;00m PostProcessingError(\u001b[39m'\u001b[39m\u001b[39mffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "\u001b[1;31mPostProcessingError\u001b[0m: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mDownloadError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 31\u001b[0m\n\u001b[0;32m     20\u001b[0m ydl_opts \u001b[39m=\u001b[39m {\n\u001b[0;32m     21\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mm4a/bestaudio/best\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mouttmpl\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m%(id)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m%(ext)s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     }]\n\u001b[0;32m     28\u001b[0m }\n\u001b[0;32m     30\u001b[0m \u001b[39mwith\u001b[39;00m yt_dlp\u001b[39m.\u001b[39mYoutubeDL(ydl_opts) \u001b[39mas\u001b[39;00m ydl:\n\u001b[1;32m---> 31\u001b[0m     error_code \u001b[39m=\u001b[39m ydl\u001b[39m.\u001b[39;49mdownload([URL])\n\u001b[0;32m     32\u001b[0m     list_video_info \u001b[39m=\u001b[39m [ydl\u001b[39m.\u001b[39mextract_info(URL, download\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)]\n\u001b[0;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m video_info \u001b[39min\u001b[39;00m list_video_info:\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3369\u001b[0m, in \u001b[0;36mYoutubeDL.download\u001b[1;34m(self, url_list)\u001b[0m\n\u001b[0;32m   3366\u001b[0m     \u001b[39mraise\u001b[39;00m SameFileError(outtmpl)\n\u001b[0;32m   3368\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m url_list:\n\u001b[1;32m-> 3369\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__download_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_info)(\n\u001b[0;32m   3370\u001b[0m         url, force_generic_extractor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mforce_generic_extractor\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m))\n\u001b[0;32m   3372\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_retcode\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3344\u001b[0m, in \u001b[0;36mYoutubeDL.__download_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3341\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   3342\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3343\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3344\u001b[0m         res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   3345\u001b[0m     \u001b[39mexcept\u001b[39;00m UnavailableVideoError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   3346\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreport_error(e)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:1507\u001b[0m, in \u001b[0;36mYoutubeDL.extract_info\u001b[1;34m(self, url, download, ie_key, extra_info, process, force_generic_extractor)\u001b[0m\n\u001b[0;32m   1505\u001b[0m             \u001b[39mraise\u001b[39;00m ExistingVideoReached()\n\u001b[0;32m   1506\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__extract_info(url, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_info_extractor(key), download, extra_info, process)\n\u001b[0;32m   1508\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1509\u001b[0m     extractors_restricted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mallowed_extractors\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, [\u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:1518\u001b[0m, in \u001b[0;36mYoutubeDL._handle_extraction_exceptions.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1517\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1519\u001b[0m     \u001b[39mexcept\u001b[39;00m (DownloadCancelled, LazyList\u001b[39m.\u001b[39mIndexError, PagedList\u001b[39m.\u001b[39mIndexError):\n\u001b[0;32m   1520\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:1615\u001b[0m, in \u001b[0;36mYoutubeDL.__extract_info\u001b[1;34m(self, url, ie, download, extra_info, process)\u001b[0m\n\u001b[0;32m   1613\u001b[0m \u001b[39mif\u001b[39;00m process:\n\u001b[0;32m   1614\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_video(ie_result)\n\u001b[1;32m-> 1615\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_ie_result(ie_result, download, extra_info)\n\u001b[0;32m   1616\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1617\u001b[0m     \u001b[39mreturn\u001b[39;00m ie_result\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:1674\u001b[0m, in \u001b[0;36mYoutubeDL.process_ie_result\u001b[1;34m(self, ie_result, download, extra_info)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[39mif\u001b[39;00m result_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1673\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_extra_info(ie_result, extra_info)\n\u001b[1;32m-> 1674\u001b[0m     ie_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_video_result(ie_result, download\u001b[39m=\u001b[39;49mdownload)\n\u001b[0;32m   1675\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_pending_errors(ie_result)\n\u001b[0;32m   1676\u001b[0m     additional_urls \u001b[39m=\u001b[39m (ie_result \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39madditional_urls\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:2779\u001b[0m, in \u001b[0;36mYoutubeDL.process_video_result\u001b[1;34m(self, info_dict, download)\u001b[0m\n\u001b[0;32m   2777\u001b[0m downloaded_formats\u001b[39m.\u001b[39mappend(new_info)\n\u001b[0;32m   2778\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2779\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_info(new_info)\n\u001b[0;32m   2780\u001b[0m \u001b[39mexcept\u001b[39;00m MaxDownloadsReached:\n\u001b[0;32m   2781\u001b[0m     max_downloads_reached \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:3325\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[1;34m(self, info_dict)\u001b[0m\n\u001b[0;32m   3323\u001b[0m     replace_info_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_process(dl_filename, info_dict, files_to_move))\n\u001b[0;32m   3324\u001b[0m \u001b[39mexcept\u001b[39;00m PostProcessingError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3325\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreport_error(\u001b[39m'\u001b[39;49m\u001b[39mPostprocessing: \u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m \u001b[39mstr\u001b[39;49m(err))\n\u001b[0;32m   3326\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   3327\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:1015\u001b[0m, in \u001b[0;36mYoutubeDL.report_error\u001b[1;34m(self, message, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreport_error\u001b[39m(\u001b[39mself\u001b[39m, message, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1011\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[39m    Do the same as trouble, but prefixes the message with 'ERROR:', colored\u001b[39;00m\n\u001b[0;32m   1013\u001b[0m \u001b[39m    in red if stderr is a tty file.\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m-> 1015\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrouble(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_err(\u001b[39m\"\u001b[39m\u001b[39mERROR:\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mStyles\u001b[39m.\u001b[39mERROR)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yt_dlp\\YoutubeDL.py:955\u001b[0m, in \u001b[0;36mYoutubeDL.trouble\u001b[1;34m(self, message, tb, is_error)\u001b[0m\n\u001b[0;32m    953\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    954\u001b[0m         exc_info \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n\u001b[1;32m--> 955\u001b[0m     \u001b[39mraise\u001b[39;00m DownloadError(message, exc_info)\n\u001b[0;32m    956\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_retcode \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "\u001b[1;31mDownloadError\u001b[0m: ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location"
          ]
        }
      ],
      "source": [
        "#@markdown # **Video selection** üì∫\n",
        "\n",
        "#@markdown Enter the URL of the Youtube video you want to transcribe, wether you want to save the audio file in your Google Drive, and run the cell.\n",
        "\n",
        "Type = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive']\n",
        "#@markdown ---\n",
        "#@markdown #### **Youtube video or playlist**\n",
        "URL = \"https://youtu.be/L_Guz73e6fw\" #@param {type:\"string\"}\n",
        "# store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Google Drive video, audio (mp4, wav), or folder containing video and/or audio files**\n",
        "video_path = \"Colab Notebooks/transcription/my_video.mp4\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    \n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "        'postprocessors': [{  # Extract audio using ffmpeg\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        error_code = ydl.download([URL])\n",
        "        list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "        \n",
        "    for video_info in list_video_info:\n",
        "        video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "            if video_path_drive.is_file():\n",
        "                display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "            elif video_path_drive.is_dir():\n",
        "                display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "            else:\n",
        "                display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "            video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "            shutil.copy(video_path_drive, video_path_local)\n",
        "            video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "-X0qB9JAzMLY"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Run the model** üöÄ\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** ‚öôÔ∏è\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"English\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "output_format = 'all' #@param ['txt', 'vtt', 'srt', 'tsv', 'json', 'all']\n",
        "#@markdown > Type of file to generate to record the transcription.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <br/>\n",
        "\n",
        "#@markdown ### **Optional: Fine tunning** \n",
        "#@markdown ---\n",
        "temperature = 0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to use for sampling.\n",
        "#@markdown ---\n",
        "temperature_increment_on_fallback = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to increase when falling back when the decoding fails to meet either of the thresholds below.\n",
        "#@markdown ---\n",
        "best_of = 5 #@param {type:\"integer\"}\n",
        "#@markdown > Number of candidates when sampling with non-zero temperature.\n",
        "#@markdown ---\n",
        "beam_size = 8 #@param {type:\"integer\"}\n",
        "#@markdown > Number of beams in beam search, only applicable when temperature is zero.\n",
        "#@markdown ---\n",
        "patience = 1.0 #@param {type:\"number\"}\n",
        "#@markdown > Optional patience value to use in beam decoding, as in [*Beam Decoding with Controlled Patience*](https://arxiv.org/abs/2204.05424), the default (1.0) is equivalent to conventional beam search.\n",
        "#@markdown ---\n",
        "length_penalty = -0.05 #@param {type:\"slider\", min:-0.05, max:1, step:0.05}\n",
        "#@markdown > Optional token length penalty coefficient (alpha) as in [*Google's Neural Machine Translation System*](https://arxiv.org/abs/1609.08144), set to negative value to uses simple length normalization.\n",
        "#@markdown ---\n",
        "suppress_tokens = \"-1\" #@param {type:\"string\"}\n",
        "#@markdown > Comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations.\n",
        "#@markdown ---\n",
        "initial_prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown > Optional text to provide as a prompt for the first window.\n",
        "#@markdown ---\n",
        "condition_on_previous_text = True #@param {type:\"boolean\"}\n",
        "#@markdown > if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop.\n",
        "#@markdown ---\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "#@markdown > whether to perform inference in fp16.\n",
        "#@markdown ---\n",
        "compression_ratio_threshold = 2.4 #@param {type:\"number\"}\n",
        "#@markdown > If the gzip compression ratio is higher than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "logprob_threshold = -1.0 #@param {type:\"number\"}\n",
        "#@markdown > If the average log probability is lower than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "no_speech_threshold = 0.6 #@param {type:\"slider\", min:-0.0, max:1, step:0.05}\n",
        "#@markdown > If the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "args = dict(\n",
        "    language = (None if language == \"Auto detection\" else language),\n",
        "    verbose = verbose_lut[verbose],\n",
        "    task = task,\n",
        "    temperature = temperature,\n",
        "    temperature_increment_on_fallback = temperature_increment_on_fallback,\n",
        "    best_of = best_of,\n",
        "    beam_size = beam_size,\n",
        "    patience=patience,\n",
        "    length_penalty=(length_penalty if length_penalty>=0.0 else None),\n",
        "    suppress_tokens=suppress_tokens,\n",
        "    initial_prompt=(None if not initial_prompt else initial_prompt),\n",
        "    condition_on_previous_text=condition_on_previous_text,\n",
        "    fp16=fp16,\n",
        "    compression_ratio_threshold=compression_ratio_threshold,\n",
        "    logprob_threshold=logprob_threshold,\n",
        "    no_speech_threshold=no_speech_threshold\n",
        ")\n",
        "\n",
        "temperature = args.pop(\"temperature\")\n",
        "temperature_increment_on_fallback = args.pop(\"temperature_increment_on_fallback\")\n",
        "if temperature_increment_on_fallback is not None:\n",
        "    temperature = tuple(np.arange(temperature, 1.0 + 1e-6, temperature_increment_on_fallback))\n",
        "else:\n",
        "    temperature = [temperature]\n",
        "\n",
        "if Model.endswith(\".en\") and args[\"language\"] not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{args['language']}'; using English instead.\")\n",
        "    args[\"language\"] = \"en\"\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    display(Markdown(f\"### {video_path_local}\"))\n",
        "\n",
        "    video_transcription = whisper.transcribe(\n",
        "        whisper_model,\n",
        "        str(video_path_local),\n",
        "        temperature=temperature,\n",
        "        **args,\n",
        "    )\n",
        "\n",
        "    # Save output\n",
        "    whisper.utils.get_writer(\n",
        "        output_format=output_format,\n",
        "        output_dir=video_path_local.parent\n",
        "    )(\n",
        "        video_transcription,\n",
        "        str(video_path_local.stem),\n",
        "        options=dict(\n",
        "            highlight_words=False,\n",
        "            max_line_count=None,\n",
        "            max_line_width=None,\n",
        "        )\n",
        "    )\n",
        "    try:\n",
        "        if output_format==\"all\":\n",
        "            for ext in ('txt', 'vtt', 'srt', 'tsv', 'json'):\n",
        "                transcript_file_name = video_path_local.stem + \".\" + ext\n",
        "                shutil.copy(\n",
        "                    video_path_local.parent / transcript_file_name,\n",
        "                    drive_whisper_path / transcript_file_name\n",
        "                )\n",
        "                display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "        else:\n",
        "            transcript_file_name = video_path_local.stem + \".\" + output_format\n",
        "            shutil.copy(\n",
        "                video_path_local.parent / transcript_file_name,\n",
        "                drive_whisper_path / transcript_file_name\n",
        "            )\n",
        "            display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "\n",
        "    except:\n",
        "        display(Markdown(f\"**Transcript file created: {transcript_local_path}**\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad6n1m4deAHp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
